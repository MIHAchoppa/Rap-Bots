## 🎤 RapBots – From Idea to a Working Prototype  

Below is a **step‑by‑step roadmap** that ties together every piece you mentioned:

| **Component** | **What it does** | **Tech / API** | **Key Tasks** |
|--------------|----------------|----------------|--------------|
| **1️⃣ Fine‑tune a Groq model** | Learn the “rap‑style” language from your own data (rhymes, metaphors, double‑/triple‑entendres, etc.). | Groq Fine‑Tuning API (Beta) | • Prepare data → upload → create fine‑tune → store ID |
| **2️⃣ Prompt‑engine (core AI)** | Send the user’s verse to the fine‑tuned model and get a reply that respects difficulty, profanity‑switch, and rhyme constraints. | Groq inference (same model) + Prompt‑engineering | • Prompt template <br>• Temperature & token limits (difficulty) <br>• Profanity toggle |
| **3️⃣ Text‑to‑Speech + Lip‑Sync** | Convert the AI‑generated rap to speech & sync the avatar’s mouth. | **MuseTalk** (`https://github.com/TMElyralab/MuseTalk`) – a local TTS‑to‑avatar server. |
| **4️⃣ Avatar & UI** | Show a 3‑D rap‑battle avatar that reacts (mad, excited, etc.) and displays the generated lyrics. | Three.js / Babylon.js + WebGL, or Unity if you prefer a desktop app. |
| **5️⃣ Battle‑Logic & Scoring** | Compare your flow to the AI’s, score rhyme density, meter, vocabulary, and “battle‑score”. | Custom scoring script (Python) + optional “judge” LLM. |
| **6️⃣ Persistence & Leaderboard** | Store each user’s battle history, difficulty levels, scores, and preferences (e.g., profanity switch). | SQLite / PostgreSQL + simple API (FastAPI/Express). |
| **7️⃣ Deployment** | Run the whole stack (API, MuseTalk, UI) on a VPS / local machine. | Docker‑compose (API + MuseTalk + DB) – one‑click start. |

---

## 1️⃣ Fine‑tuning a Groq Model – Quick‑Start Script  

> **Prerequisite:** You need a **Groq API key** (`GROQ_API_KEY`). If you haven’t received access to the beta, contact Groq’s support first.

### 1️⃣.1 Prepare Your Training Data  

Fine‑tune with **JSON‑Lines** (`.jsonl`) where each line is a **`prompt` / `completion`** pair.  
Below is a *minimal* example of a rap line dataset:


{"prompt":"<USER> I'm feeling the vibe. Give me a 4‑line rap about “night”.\n","completion":"<BOT> Night sky’s a canvas, moon’s bright paint, / I spin the verses, no restraint, / Shadows whisper, rhythm’s saint, / I’m the night‑mare, never faint."}
{"prompt":"<USER> Use a metaphor and a double‑entendre about “money”.\n","completion":"<BOT> Money’s a river, flowin’ thick, / My pockets flood, they ain’t so slick, / When I cash, the beats *cash* out, / Cash flow’s a flow, no doubt."}



- **`<USER>`** and **`<BOT>`** delimiters make it easy to tell the model what’s a user prompt and what’s a generated response.
- Include **difficulty tags** in the prompt if you want the model to learn how to adapt (see *Prompt‑engine* section).

**Save** this file as `rap_dataset.jsonl`.

### 1️⃣.2 Upload the Training File  


# 1️⃣ Upload file → get a file_id
curl https://api.groq.com/v1/files -s \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -F "purpose=Fine-tuning" \
  -F "file=@rap_dataset.jsonl"
Response (excerpt):


{
  "id":"file-abc123",
  "object":"file",
  "filename":"rap_dataset.jsonl",
  "purpose":"fine-tuning",
  "created_at":1723524000
}
Take note of file_id (e.g., file-abc123). You’ll need it for the next step.

1️⃣.3 Create the Fine‑Tune

curl https://api.groq.com/v1/fine_tunings -s \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
        "input_file_id": "file-abc123",
        "name": "rapbots_lora",
        "type": "lora",
        "base_model": "llama-3.2-8b-instant"
      }'
Result (example):


{
  "id":"ft-xyz987",
  "object":"object",
  "data":{
    "id":"ft-xyz987",
    "name":"rapbots_lora",
    "base_model":"llama-3.2-8b-instant",
    "type":"lora",
    "input_file_id":"file-abc123",
    "created_at":1723525000,
    "fine_tuned_model":"llama-3.2-8b-instant-rap"
  }
}
Store the returned fine_tuned_model name. You’ll call it for inference:

model = "llama-3.2-8b-instant-rap"
2️⃣ Prompt‑Engine (Generating Rap Lines)
2️⃣.1 Prompt Template (Python)

import os, requests, json

API_KEY = os.getenv("GROQ_API_KEY")
MODEL   = "llama-3.2-8b-instant-rap"   # <‑‑ from fine‑tune

def generate_rap(
    user_prompt: str,
    difficulty: str = "normal",   # "easy", "hard"
    profanity: bool = False,
    max_tokens: int = 120,
    temperature: float = 0.8
):
    # Adjust temperature per difficulty
    temp_map = {"easy": 0.7, "normal": 0.8, "hard": 1.0}
    # Simple profanity filter toggle (uses OpenAI’s moderation endpoint as example)
    if profanity:
        # you could also use a simple word list or a model
        # here we just set a higher temperature to allow strong language
        temp = temp_map.get(difficulty, 0.8) + 0.2
    else:
        temp = temp_map.get(difficulty, 0.8)

    prompt = f"""<USER> {user_prompt}
<PROF> {'ON' if profanity else 'OFF'}   # internal flag
<DIF>{difficulty.upper()}</DIF>

"""
    payload = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": max_tokens,
        "temperature": temp,
        "top_p": 0.9,
        "stream": False,
    }

    response = requests.post(
        "https://api.groq.com/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json",
        },
        json=payload,
    )
    response.raise_for_status()
    return response.json()["choices"][0]["message"]["content"].strip()



**How it works**

* **`<PROF>`** – internal flag used to decide if profanity is allowed.  
* **`<DIF>`** – tells the model what difficulty level you want; you can train the model to respond differently (e.g., more complex rhymes at “hard”).  
* **`temperature`** is tweaked automatically based on difficulty & profanity.

**Call example**


print(generate_rap(
    "Give me a 8‑line battle rap about “gravity”.",
    difficulty="hard",
    profanity=False
))
The model will try to output:

Syllable‑matched rhymes (perfect & near‑rhymes).
Metaphors, idioms, similes (as it learned from the dataset).
No profanity unless profanity=True.
3️⃣ Real‑Time Lip‑Sync with MuseTalk
Clone & install MuseTalk (requires ffmpeg and a CUDA GPU for best TTS speed).

git clone https://github.com/TMElyralab/MuseTalk
cd MuseTalk
pip install -r requirements.txt
Start the server (default port 5000).

python app.py --port 5000
The API offers an endpoint:

POST /v1/tts
{
   "text": "<generated rap lines>",
   "speaker_id": 0
}
It returns audio.wav and mouth_shape.npy (mouth‑shape animation data).

3️⃣.1 Hooking Up the Avatar (Web)

<script src="https://cdn.jsdelivr.net/npm/three@0.165.0/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@muse-talk/client@1.0.0/dist/museTalkClient.min.js"></script>

<script>
async function rapBattle(userPrompt) {
   // 1. Get rap line from Groq
   const rap = await fetch('/api/generate', {
     method: 'POST',
     headers: {'Content-Type':'application/json'},
     body: JSON.stringify({prompt: userPrompt})
   }).then(r=>r.json());

   // 2. Send to MuseTalk for audio + mouth data
   const resp = await fetch('http://localhost:5000/v1/tts', {
        method: 'POST',
        body: JSON.stringify({ text: rap.text })
   });
   const {audio, mouth} = await resp.json();

   // 3. Play audio
   const audioEl = new Audio('data:audio/wav;base64,'+audio);
   audioEl.play();

   // 4. Drive avatar mouth (simplified)
   const avatar = await loadYourAvatar(); // e.g., load a GLTF model
   avatar.setMouthShape(mouth);
}
</script>
The loadYourAvatar() function would load a 3‑D avatar (GLTF/GLB). You can use any 3‑D model that has blend‑shape targets named mouthA, mouthE, etc., matching the shape array returned by MuseTalk.

4️⃣ Avatar Reactions & “Mad” State
You can drive avatar emotions with a simple state machine:

State	Trigger	Avatar Reaction
idle	user starts battle	neutral pose
battle	AI replies	lip‑sync + gestures
mad	user “insults” (detect profanity or aggressive phrasing)	angry facial expression + higher‑pitch voice
victory	AI scores higher	celebratory animation
defeat	AI scores higher	sad or angry pose
Implementation (Pseudo‑code)


class Avatar:
    def __init__(self):
        self.state = "idle"
    def react(self, event):
        if event == "user_insult" and not self.profanity_allowed:
            self.state = "mad"
            self.play_animation('angry')
        elif event == "ai_win":
            self.state = "defeat"
            self.play_animation('sad')
        elif event == "user_win":
            self.state = "victory"
            self.play_animation('celebrate')
        else:
            self.state = "idle"
You can expose these states to the front‑end via WebSocket so the UI updates in real‑time.

5️⃣ Battle Scoring Engine (Python)
A simple scoring heuristic:

Metric	Weight
Rhyme density (perfect + near)	0.4
Meter/ syllable count match	0.2
Lexical richness (unique words / total)	0.15
Metaphor/idiom count	0.15
Profanity penalty (if disabled)	-0.1
5.1 Sample Scorer

import re
from collections import Counter

def rhyme_score(text):
    # naive rhyme: check last 2‑3 letters of each line
    lines = [l.strip() for l in text.split('\n') if l]
    endings = [re.sub(r'[^a-z]','',line.lower().split()[-1])[-3:] for line in lines]
    # Count how many endings repeat (perfect rhyme) or share first 2 letters (near)
    cnt = Counter(endings)
    return max(cnt.values()) / len(endings)   # 0..1

def meter_score(text):
    # Approximate syllable count per line (simple heuristic)
    syllables = [sum(1 for c in word if c in "aeiouy") for line in text.split('\n') for word in line.split()]
    # Ideal: ~8 syllables per line in battle rap
    ideal = 8
    diff = sum(abs(s-ideal) for s in syllables) / len(syllables)
    return max(0, 1 - diff/5)  # higher is better

def lexical_score(text):
    words = re.findall(r'\b\w+\b', text.lower())
    uniq = len(set(words))
    return uniq / len(words)

def metaphor_score(text):
    # look for known metaphor words (list can be expanded)
    metaphors = ['like', 'as', 'like a', 'as if', 'as though', 'resemble', 'mirror', 'reflect']
    count = sum(text.lower().count(w) for w in metaphors)
    return min(1, count/3)   # 0..1

def profanity_penalty(text, profanity_allowed):
    # simple word list
    bad = {'fuck','shit','bitch','ass'}
    hit = any(w in bad for w in text.lower().split())
    return -0.1 if (hit and not profanity_allowed) else 0

def battle_score(user_text, ai_text, profanity_allowed=False):
    # user vs AI; higher score wins
    user_score = 0.4*rhyme_score(user_text) + \
                 0.2*meter_score(user_text) + \
                 0.15*lexical_score(user_text) + \
                 0.15*metaphor_score(user_text) + \
                 0.1*penalty(user_text, False)   # user no profanity

    ai_score = 0.4*rhyme_score(ai_text) + \
               0.2*meter_score(ai_text) + \
               0.15*lexical_score(ai_text) + \
               0.15*metaphor_score(ai_text) + \
               0.1*penalty(ai_text, True)

    return {"user":user_score, "ai":ai_score}
The result can be sent back to the UI to show a progress bar, score number, and ranking (e.g., “You’re 0.12 points behind the AI”).

📦 Putting It All Together – Minimal Docker‑Compose

version: "3.9"
services:
  groq-proxy:               # thin wrapper for your Python API
    build: ./groq-api
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
    ports: ["8000:8000"]
  muse-talk:
    image: tmeilyra/musetalk:latest
    ports: ["5000:5000"]
    # optional: mount a custom avatar folder
    volumes:
      - ./avatars:/app/avatars
  web-ui:
    build: ./frontend
    ports: ["8080:80"]
    depends_on: [groq-proxy, muse-talk]
groq-api – a tiny FastAPI server exposing /generate (the generate_rap function) and /score endpoints.
muse-talk – the official MuseTalk Docker image (if you build it yourself).
web-ui – static HTML/JS (see snippet above) served via Nginx.
Run:


docker compose up -d



Visit <http://localhost:8080> to start battling the AI!

---

## 🛠️ What’s Needed From You

| Item | Reason | Example |
|------|--------|--------|
| **Groq API key** | To call the fine‑tuning and inference endpoints | `export GROQ_API_KEY=…` |
| **Training data** (rap lines) | The model learns your style, metaphors, etc. | 10k‑20k lines in JSONL |
| **Avatar model** (GLTF/GLB) with mouth blend‑shapes | For MuseTalk lip‑sync | `avatar.glb` with `mouthA`, `mouthE`, `mouthO` |
| **GPU / ffmpeg** (optional) | MuseTalk uses TTS+audio; GPU speeds up speech | NVIDIA‑CUDA 11+ |
| **Hosting choice** (local PC, cloud VM, Docker) | To run all services together | Windows PC or Linux VPS |

---

## 📚 Next Steps

1. **Create / upload your rap dataset** (or let me generate a sample for you).  
2. **Generate your first fine‑tune** using the scripts above.  
3. **Spin up MuseTalk** (or let me set up a Docker container for you).  
4 **Deploy the FastAPI wrapper** (I can give you a ready‑to‑run `app.py`).  
5. **Add avatar assets** and wire the front‑end (the HTML snippet above).  
6. **Run a demo battle** and tune the scoring weights.

Let me know **which parts you’d like to dive into first** (e.g., data prep, code scaffolding, Docker setup, or UI design) and I’ll provide the exact files / commands you need. 🚀
10:44 AM